#!/usr/bin/env python3
"""
Milvus í•™ìŠµ í”„ë¡œì íŠ¸ - 2ë‹¨ê³„: ê²€ìƒ‰ ìµœì í™” ì‹¤ìŠµ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Milvusì˜ ê²€ìƒ‰ ìµœì í™” ê¸°ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.
- ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ìµœì í™”
- í•„í„°ë§ê³¼ ê²€ìƒ‰ ì¡°í•©
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
- ê²€ìƒ‰ ì„±ëŠ¥ ë¶„ì„
"""

import sys
import os
import time
import numpy as np
from typing import List, Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from common.connection import MilvusConnection
from common.vector_utils import VectorUtils
from common.data_loader import DataLoader
from pymilvus import Collection, utility, FieldSchema, CollectionSchema, DataType


class SearchOptimizer:
    """Milvus ê²€ìƒ‰ ìµœì í™” í´ë˜ìŠ¤"""
    
    def __init__(self, connection: MilvusConnection):
        self.connection = connection
        self.vector_utils = VectorUtils()
        self.data_loader = DataLoader()
        self.collection_name = "search_optimization_demo"
        
    def create_demo_collection(self) -> Collection:
        """ë°ëª¨ìš© ì»¬ë ‰ì…˜ ìƒì„±"""
        print(f"\nğŸ“ ì»¬ë ‰ì…˜ '{self.collection_name}' ìƒì„± ì¤‘...")
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
        if utility.has_collection(self.collection_name):
            utility.drop_collection(self.collection_name)
            print(f"  ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œë¨")
        
        # ìŠ¤í‚¤ë§ˆ ì •ì˜ (ë” ë‹¤ì–‘í•œ í•„ë“œ)
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=500),
            FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=2000),
            FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=384),
            FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=50),
            FieldSchema(name="author", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="publish_year", dtype=DataType.INT64),
            FieldSchema(name="rating", dtype=DataType.FLOAT),
            FieldSchema(name="view_count", dtype=DataType.INT64),
            FieldSchema(name="is_featured", dtype=DataType.BOOL)
        ]
        
        schema = CollectionSchema(
            fields=fields,
            description="ê²€ìƒ‰ ìµœì í™” ë°ëª¨ ì»¬ë ‰ì…˜"
        )
        
        collection = Collection(name=self.collection_name, schema=schema)
        print(f"  âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")
        return collection
    
    def generate_demo_data(self, count: int = 50000) -> List[List]:
        """ë°ëª¨ ë°ì´í„° ìƒì„±"""
        print(f"\nğŸ“Š ë°ëª¨ ë°ì´í„° {count}ê°œ ìƒì„± ì¤‘...")
        
        categories = ["Technology", "Science", "Business", "Health", "Education", "Entertainment"]
        authors = [f"Author_{i}" for i in range(1, 101)]  # 100ëª…ì˜ ì €ì
        
        titles = []
        contents = []
        category_list = []
        author_list = []
        years = []
        ratings = []
        view_counts = []
        featured_flags = []
        
        for i in range(count):
            category = np.random.choice(categories)
            author = np.random.choice(authors)
            year = np.random.randint(2020, 2025)
            
            title = f"{category} Article {i}: Advanced concepts and applications"
            content = f"This is a comprehensive article about {category.lower()} " \
                     f"written by {author} in {year}. It covers various topics " \
                     f"and provides detailed insights into the subject matter."
            
            titles.append(title)
            contents.append(content)
            category_list.append(category)
            author_list.append(author)
            years.append(year)
            ratings.append(np.random.uniform(1.0, 5.0))
            view_counts.append(np.random.randint(100, 100000))
            featured_flags.append(np.random.choice([True, False], p=[0.1, 0.9]))
        
        # ë²¡í„° ë³€í™˜ (ì œëª©ê³¼ ë‚´ìš© ê²°í•©)
        print("  ë²¡í„° ë³€í™˜ ì¤‘...")
        combined_texts = [f"{title} {content}" for title, content in zip(titles, contents)]
        vectors = self.vector_utils.texts_to_vectors(combined_texts)
        
        data = [
            titles,
            contents,
            vectors.tolist(),
            category_list,
            author_list,
            years,
            ratings,
            view_counts,
            featured_flags
        ]
        
        print(f"  âœ… ë°ëª¨ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        return data
    
    def insert_and_index_data(self, collection: Collection, data: List[List]) -> None:
        """ë°ì´í„° ì‚½ì… ë° ì¸ë±ìŠ¤ ìƒì„±"""
        print(f"\nğŸ’¾ ë°ì´í„° ì‚½ì… ì¤‘...")
        start_time = time.time()
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ì‚½ì…
        batch_size = 10000
        total_count = len(data[0])
        
        for i in range(0, total_count, batch_size):
            end_idx = min(i + batch_size, total_count)
            batch_data = [field[i:end_idx] for field in data]
            collection.insert(batch_data)
            print(f"  ë°°ì¹˜ {i//batch_size + 1} ì‚½ì… ì™„ë£Œ ({end_idx - i}ê°œ)")
        
        collection.flush()
        print(f"  âœ… ì „ì²´ ë°ì´í„° ì‚½ì… ì™„ë£Œ ({time.time() - start_time:.2f}ì´ˆ)")
        
        # ì¸ë±ìŠ¤ ìƒì„±
        print(f"\nğŸ” ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        start_time = time.time()
        
        index_params = {
            "metric_type": "L2",
            "index_type": "HNSW",
            "params": {"M": 16, "efConstruction": 200}
        }
        
        collection.create_index(field_name="vector", index_params=index_params)
        print(f"  âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ ({time.time() - start_time:.2f}ì´ˆ)")
    
    def basic_search_demo(self, collection: Collection) -> None:
        """ê¸°ë³¸ ê²€ìƒ‰ ë°ëª¨"""
        print("\n" + "="*60)
        print(" ğŸ” ê¸°ë³¸ ê²€ìƒ‰ ë°ëª¨")
        print("="*60)
        
        collection.load()
        
        # ê²€ìƒ‰ ì¿¼ë¦¬
        query_text = "advanced technology artificial intelligence machine learning"
        query_vectors = self.vector_utils.text_to_vector(query_text)
        query_vector = query_vectors[0] if len(query_vectors.shape) > 1 else query_vectors
        
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: '{query_text}'")
        
        # ê¸°ë³¸ ê²€ìƒ‰
        print("\n1. ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰")
        start_time = time.time()
        
        search_params = {"metric_type": "L2", "params": {"ef": 100}}
        results = collection.search(
            data=[query_vector],
            anns_field="vector",
            param=search_params,
            limit=10,
            output_fields=["title", "category", "author", "rating"]
        )
        
        search_time = time.time() - start_time
        print(f"ê²€ìƒ‰ ì‹œê°„: {search_time:.4f}ì´ˆ")
        
        for i, hit in enumerate(results[0]):
            print(f"  {i+1}. {hit.entity.get('title')[:50]}...")
            print(f"      ì¹´í…Œê³ ë¦¬: {hit.entity.get('category')}, "
                  f"ì €ì: {hit.entity.get('author')}, "
                  f"í‰ì : {hit.entity.get('rating'):.2f}, "
                  f"ê±°ë¦¬: {hit.distance:.4f}")
    
    def filtered_search_demo(self, collection: Collection) -> None:
        """í•„í„°ë§ ê²€ìƒ‰ ë°ëª¨"""
        print("\n" + "="*60)
        print(" ğŸ¯ í•„í„°ë§ ê²€ìƒ‰ ë°ëª¨")
        print("="*60)
        
        query_text = "business strategy and innovation"
        query_vectors = self.vector_utils.text_to_vector(query_text)
        query_vector = query_vectors[0] if len(query_vectors.shape) > 1 else query_vectors
        
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: '{query_text}'")
        
        # 1. ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        print("\n1. ì¹´í…Œê³ ë¦¬ í•„í„°: Business")
        start_time = time.time()
        
        results = collection.search(
            data=[query_vector],
            anns_field="vector",
            param={"metric_type": "L2", "params": {"ef": 100}},
            limit=5,
            expr='category == "Business"',
            output_fields=["title", "category", "rating"]
        )
        
        search_time = time.time() - start_time
        print(f"ê²€ìƒ‰ ì‹œê°„: {search_time:.4f}ì´ˆ")
        
        for i, hit in enumerate(results[0]):
            print(f"  {i+1}. {hit.entity.get('title')[:50]}...")
            print(f"      ì¹´í…Œê³ ë¦¬: {hit.entity.get('category')}, "
                  f"í‰ì : {hit.entity.get('rating'):.2f}")
        
        # 2. ë³µí•© í•„í„°ë§
        print("\n2. ë³µí•© í•„í„°: Technology + ë†’ì€ í‰ì  + ìµœê·¼ ë…„ë„")
        start_time = time.time()
        
        results = collection.search(
            data=[query_vector],
            anns_field="vector",
            param={"metric_type": "L2", "params": {"ef": 100}},
            limit=5,
            expr='category == "Technology" and rating > 4.0 and publish_year >= 2023',
            output_fields=["title", "category", "rating", "publish_year"]
        )
        
        search_time = time.time() - start_time
        print(f"ê²€ìƒ‰ ì‹œê°„: {search_time:.4f}ì´ˆ")
        
        for i, hit in enumerate(results[0]):
            print(f"  {i+1}. {hit.entity.get('title')[:50]}...")
            print(f"      ì¹´í…Œê³ ë¦¬: {hit.entity.get('category')}, "
                  f"í‰ì : {hit.entity.get('rating'):.2f}, "
                  f"ë…„ë„: {hit.entity.get('publish_year')}")
        
        # 3. ë²”ìœ„ í•„í„°ë§
        print("\n3. ë²”ìœ„ í•„í„°: ì¡°íšŒìˆ˜ 10,000 ì´ìƒ")
        start_time = time.time()
        
        results = collection.search(
            data=[query_vector],
            anns_field="vector",
            param={"metric_type": "L2", "params": {"ef": 100}},
            limit=5,
            expr='view_count >= 10000',
            output_fields=["title", "view_count", "is_featured"]
        )
        
        search_time = time.time() - start_time
        print(f"ê²€ìƒ‰ ì‹œê°„: {search_time:.4f}ì´ˆ")
        
        for i, hit in enumerate(results[0]):
            print(f"  {i+1}. {hit.entity.get('title')[:50]}...")
            print(f"      ì¡°íšŒìˆ˜: {hit.entity.get('view_count')}, "
                  f"ì¶”ì²œ: {hit.entity.get('is_featured')}")
    
    def search_parameter_tuning(self, collection: Collection) -> None:
        """ê²€ìƒ‰ íŒŒë¼ë¯¸í„° íŠœë‹"""
        print("\n" + "="*60)
        print(" ğŸ›ï¸ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° íŠœë‹")
        print("="*60)
        
        query_text = "scientific research methodology"
        query_vectors = self.vector_utils.text_to_vector(query_text)
        query_vector = query_vectors[0] if len(query_vectors.shape) > 1 else query_vectors
        
        # ef íŒŒë¼ë¯¸í„° íŠœë‹
        ef_values = [50, 100, 200, 400]
        
        print("HNSW ef íŒŒë¼ë¯¸í„° ì˜í–¥ ë¶„ì„:")
        print(f"{'ef':<5} {'ê²€ìƒ‰ì‹œê°„(ì´ˆ)':<12} {'QPS':<8}")
        print("-" * 30)
        
        for ef in ef_values:
            times = []
            
            # ì—¬ëŸ¬ ë²ˆ ì¸¡ì •í•˜ì—¬ í‰ê·  ê³„ì‚°
            for _ in range(5):
                start_time = time.time()
                
                results = collection.search(
                    data=[query_vector],
                    anns_field="vector",
                    param={"metric_type": "L2", "params": {"ef": ef}},
                    limit=10,
                    output_fields=["title"]
                )
                
                search_time = time.time() - start_time
                times.append(search_time)
            
            avg_time = np.mean(times)
            qps = 1 / avg_time
            
            print(f"{ef:<5} {avg_time:<12.4f} {qps:<8.2f}")
    
    def hybrid_search_demo(self, collection: Collection) -> None:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°ëª¨"""
        print("\n" + "="*60)
        print(" ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°ëª¨")
        print("="*60)
        
        # ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ ì¡°í•©
        queries = [
            "artificial intelligence machine learning",
            "business strategy management",
            "scientific research methodology"
        ]
        
        query_vectors = []
        for q in queries:
            qv = self.vector_utils.text_to_vector(q)
            query_vectors.append(qv[0] if len(qv.shape) > 1 else qv)
        
        print("ë‹¤ì¤‘ ì¿¼ë¦¬ ê²€ìƒ‰:")
        start_time = time.time()
        
        # ì—¬ëŸ¬ ë²¡í„°ë¡œ ë™ì‹œ ê²€ìƒ‰
        results = collection.search(
            data=query_vectors,
            anns_field="vector",
            param={"metric_type": "L2", "params": {"ef": 100}},
            limit=3,
            output_fields=["title", "category"]
        )
        
        search_time = time.time() - start_time
        print(f"ê²€ìƒ‰ ì‹œê°„: {search_time:.4f}ì´ˆ")
        
        for i, (query, result) in enumerate(zip(queries, results)):
            print(f"\nì¿¼ë¦¬ {i+1}: '{query}'")
            for j, hit in enumerate(result):
                print(f"  {j+1}. {hit.entity.get('title')[:40]}... "
                      f"({hit.entity.get('category')})")
    
    def performance_analysis(self, collection: Collection) -> None:
        """ì„±ëŠ¥ ë¶„ì„"""
        print("\n" + "="*60)
        print(" ğŸ“Š ì„±ëŠ¥ ë¶„ì„")
        print("="*60)
        
        query_text = "technology innovation development"
        query_vectors = self.vector_utils.text_to_vector(query_text)
        query_vector = query_vectors[0] if len(query_vectors.shape) > 1 else query_vectors
        
        # ë‹¤ì–‘í•œ ì¡°ê±´ì—ì„œ ì„±ëŠ¥ ì¸¡ì •
        test_cases = [
            {"name": "ê¸°ë³¸ ê²€ìƒ‰", "limit": 10, "expr": None},
            {"name": "í•„í„°ë§ ê²€ìƒ‰", "limit": 10, "expr": 'category == "Technology"'},
            {"name": "ë³µí•© í•„í„°ë§", "limit": 10, "expr": 'category == "Technology" and rating > 3.0'},
            {"name": "ëŒ€ëŸ‰ ê²°ê³¼", "limit": 100, "expr": None},
        ]
        
        print(f"{'í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤':<15} {'í‰ê· ì‹œê°„(ì´ˆ)':<12} {'QPS':<8} {'ê²°ê³¼ìˆ˜':<6}")
        print("-" * 50)
        
        for case in test_cases:
            times = []
            result_count = 0
            
            for _ in range(3):
                start_time = time.time()
                
                results = collection.search(
                    data=[query_vector],
                    anns_field="vector",
                    param={"metric_type": "L2", "params": {"ef": 100}},
                    limit=case["limit"],
                    expr=case["expr"],
                    output_fields=["title"]
                )
                
                search_time = time.time() - start_time
                times.append(search_time)
                result_count = len(results[0])
            
            avg_time = np.mean(times)
            qps = 1 / avg_time
            
            print(f"{case['name']:<15} {avg_time:<12.4f} {qps:<8.2f} {result_count:<6}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Milvus ê²€ìƒ‰ ìµœì í™” ì‹¤ìŠµ ì‹œì‘")
    print("ì‹¤í–‰ ì‹œê°„:", time.strftime('%Y-%m-%d %H:%M:%S'))
    
    try:
        # Milvus ì—°ê²°
        with MilvusConnection() as conn:
            print("âœ… Milvus ì—°ê²° ì„±ê³µ")
            
            # ê²€ìƒ‰ ìµœì í™” ë§¤ë‹ˆì € ìƒì„±
            optimizer = SearchOptimizer(conn)
            
            # 1. ë°ëª¨ ì»¬ë ‰ì…˜ ìƒì„± ë° ë°ì´í„° ì¤€ë¹„
            collection = optimizer.create_demo_collection()
            demo_data = optimizer.generate_demo_data(20000)  # 20K ë°ì´í„°
            optimizer.insert_and_index_data(collection, demo_data)
            
            # 2. ê¸°ë³¸ ê²€ìƒ‰ ë°ëª¨
            optimizer.basic_search_demo(collection)
            
            # 3. í•„í„°ë§ ê²€ìƒ‰ ë°ëª¨
            optimizer.filtered_search_demo(collection)
            
            # 4. ê²€ìƒ‰ íŒŒë¼ë¯¸í„° íŠœë‹
            optimizer.search_parameter_tuning(collection)
            
            # 5. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°ëª¨
            optimizer.hybrid_search_demo(collection)
            
            # 6. ì„±ëŠ¥ ë¶„ì„
            optimizer.performance_analysis(collection)
            
            # ì •ë¦¬
            collection.drop()
            print("\nğŸ§¹ í…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ ì •ë¦¬ ì™„ë£Œ")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\nğŸ‰ ê²€ìƒ‰ ìµœì í™” ì‹¤ìŠµ ì™„ë£Œ!")
    print("\nğŸ’¡ í•™ìŠµ í¬ì¸íŠ¸:")
    print("  â€¢ í•„í„°ë§ê³¼ ë²¡í„° ê²€ìƒ‰ì„ ì¡°í•©í•˜ì—¬ ì •í™•í•œ ê²°ê³¼ ì–»ê¸°")
    print("  â€¢ ef íŒŒë¼ë¯¸í„°ë¡œ ê²€ìƒ‰ ì •í™•ë„ì™€ ì†ë„ ì¡°ì ˆ")
    print("  â€¢ ë³µí•© ì¡°ê±´ìœ¼ë¡œ ì„¸ë°€í•œ ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •")
    print("  â€¢ ë‹¤ì¤‘ ì¿¼ë¦¬ë¡œ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ê²€ìƒ‰")
    print("  â€¢ ì„±ëŠ¥ ë¶„ì„ìœ¼ë¡œ ìµœì  ì„¤ì • ì°¾ê¸°")
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 